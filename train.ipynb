{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model import *\n",
    "import dataloader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaocheng/Research/DeepOpticsV2/GeomGenerator/dataloader.py:110: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if blob['pattern'] != None:\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/zhaocheng/Research/DeepOpticsV2/GeomData/arc\"\n",
    "data_path = \"/home/zhaocheng/Research/DeepOpticsV2/GeomData/GeomData\"\n",
    "dataloader = dl.DataLoader(data_path)\n",
    "# print(dataloader.data_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def recover_img(img, binary=False):\n",
    "    # input: the 2-D tensor image with values from 0 to 1\n",
    "    # output: 2-D greyscale image\n",
    "    img = img * 255\n",
    "    img.astype(np.int8)       \n",
    "    # img = np.stack((img, )*3, -1)\n",
    "    \n",
    "    if binary==True:\n",
    "        # res, img = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "        img[img > 127] = 255\n",
    "        img[img <= 127] = 0\n",
    "        \n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_model(encoder, decoder, losses=None, savepath='./', name=0):\n",
    "    # save net models\n",
    "    if not os.path.exists(savepath):\n",
    "        os.makedirs(savepath)\n",
    "    \n",
    "    if savepath == './':\n",
    "        path_to_save = savepath + str(name) + '/'\n",
    "    else:\n",
    "        path_to_save = savepath + '/' + str(name) + '/'\n",
    "    print(path_to_save)\n",
    "    \n",
    "    if os.path.exists(path_to_save):\n",
    "        print(\"File path {} has already been created, model will not be save unless delete the directory\".format(savepath + str(name) + '/'))\n",
    "        return 0\n",
    "\n",
    "    os.makedirs(path_to_save)\n",
    "    torch.save(encoder.state_dict(), path_to_save + 'encoder_net.pth')\n",
    "    torch.save(decoder.state_dict(), path_to_save + 'decoder_net.pth')\n",
    "    \n",
    "    if losses:\n",
    "        np.save(path_to_save + \"losses\", losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tqdm import trange\n",
    "from matplotlib import colors\n",
    "import matplotlib as mpl \n",
    "\n",
    "def train(encode_dim, niters, batchsize, dataloader, save_path=None):\n",
    "    \n",
    "    # define network\n",
    "    encoder = GeomEncoder(encode_dim, 1, 64, 64)\n",
    "    decoder = GeomDecoder(encode_dim, 0, 1, 64, 64)\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    \n",
    "    optimizer_e = optim.Adam(encoder.parameters(), lr=1e-3) \n",
    "    optimizer_d = optim.Adam(decoder.parameters(), lr=1e-3) \n",
    "    \n",
    "    loss_MSE = nn.MSELoss(size_average=True)\n",
    "    loss_L1 = nn.L1Loss()\n",
    "    \n",
    "    dataiter = dataloader.dataloader(batchsize)\n",
    "    \n",
    "    loss = []\n",
    "    \n",
    "    for n in trange(niters):\n",
    "        input_data = Variable(next(dataiter).cuda(), requires_grad=False)\n",
    "        optimizer_e.zero_grad()\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        latent = encoder(input_data)\n",
    "        reconst = decoder(latent)\n",
    "        \n",
    "        reconst_loss = loss_MSE(reconst, input_data)\n",
    "        \n",
    "        reconst_loss.backward()\n",
    "        optimizer_e.step()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        if n % 100 == 0:\n",
    "            if n % 2000 == 0:\n",
    "                if save_path != None:      \n",
    "                    save_model(encoder, decoder, losses=loss, savepath = save_path, name=str(n))\n",
    "                    \n",
    "            loss.append(reconst_loss.cpu().data.numpy()[0])\n",
    "            clear_output(True)\n",
    "            plt.plot(loss)\n",
    "            plt.show()\n",
    "            \n",
    "            # get image and comparison\n",
    "            cmap = mpl.cm.gray\n",
    "            input_img = input_data.cpu().data.numpy()[0,0,:,:]\n",
    "            recon_img = reconst.cpu().data.clamp_(0,1).numpy()[0,0,:,:]\n",
    "            input_img, recon_img = recover_img(input_img), recover_img(recon_img, binary=True)\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(input_img, cmap=cmap)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(recon_img, cmap=cmap)\n",
    "            print(loss[-1])\n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngS5JLWGgS1JL/D+2vFpzk9PCxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5bf012f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 19903/20000 [16:28<00:04, 20.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0060175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [16:32<00:00, 20.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.64733303,\n",
       " 0.38201517,\n",
       " 0.33695239,\n",
       " 0.33178213,\n",
       " 0.32083851,\n",
       " 0.31683329,\n",
       " 0.32169801,\n",
       " 0.313961,\n",
       " 0.31577861,\n",
       " 0.11358663,\n",
       " 0.031157203,\n",
       " 0.024494292,\n",
       " 0.017497217,\n",
       " 0.017371068,\n",
       " 0.015268993,\n",
       " 0.017512703,\n",
       " 0.015492305,\n",
       " 0.01374163,\n",
       " 0.016369514,\n",
       " 0.014701338,\n",
       " 0.012780679,\n",
       " 0.014941551,\n",
       " 0.014804139,\n",
       " 0.015901862,\n",
       " 0.015191086,\n",
       " 0.012027313,\n",
       " 0.010578487,\n",
       " 0.011737574,\n",
       " 0.015378105,\n",
       " 0.0122819,\n",
       " 0.013752411,\n",
       " 0.013409524,\n",
       " 0.012255116,\n",
       " 0.011916175,\n",
       " 0.011929867,\n",
       " 0.011564194,\n",
       " 0.011889019,\n",
       " 0.011900662,\n",
       " 0.012262403,\n",
       " 0.010983604,\n",
       " 0.012344154,\n",
       " 0.0099182306,\n",
       " 0.012071813,\n",
       " 0.011223952,\n",
       " 0.011228657,\n",
       " 0.011176935,\n",
       " 0.011140113,\n",
       " 0.011187589,\n",
       " 0.011265752,\n",
       " 0.01127901,\n",
       " 0.010737445,\n",
       " 0.0079388507,\n",
       " 0.010616243,\n",
       " 0.0097643621,\n",
       " 0.013712029,\n",
       " 0.0089066885,\n",
       " 0.010050977,\n",
       " 0.0098525966,\n",
       " 0.010502144,\n",
       " 0.0091340104,\n",
       " 0.0095371585,\n",
       " 0.011177558,\n",
       " 0.010765757,\n",
       " 0.0097482186,\n",
       " 0.010161287,\n",
       " 0.0099472636,\n",
       " 0.0083002588,\n",
       " 0.0098546231,\n",
       " 0.0087310597,\n",
       " 0.010468837,\n",
       " 0.0093371496,\n",
       " 0.0079475651,\n",
       " 0.0076360186,\n",
       " 0.0087461984,\n",
       " 0.0077597001,\n",
       " 0.010145967,\n",
       " 0.0092086336,\n",
       " 0.0079143671,\n",
       " 0.0080399076,\n",
       " 0.010027761,\n",
       " 0.011718179,\n",
       " 0.0089097312,\n",
       " 0.010906996,\n",
       " 0.0092418091,\n",
       " 0.0088369502,\n",
       " 0.0082673235,\n",
       " 0.0074060336,\n",
       " 0.0084902951,\n",
       " 0.008497769,\n",
       " 0.0084348815,\n",
       " 0.0074225138,\n",
       " 0.0084557608,\n",
       " 0.0069808103,\n",
       " 0.0088992044,\n",
       " 0.0069725001,\n",
       " 0.0086221332,\n",
       " 0.0091510471,\n",
       " 0.0071637244,\n",
       " 0.0074881441,\n",
       " 0.0074923555,\n",
       " 0.009420502,\n",
       " 0.00864112,\n",
       " 0.0076289093,\n",
       " 0.007920919,\n",
       " 0.006642485,\n",
       " 0.006122733,\n",
       " 0.0069510518,\n",
       " 0.0076451818,\n",
       " 0.0068223295,\n",
       " 0.0081960121,\n",
       " 0.0073717646,\n",
       " 0.0074855401,\n",
       " 0.0074395221,\n",
       " 0.007711241,\n",
       " 0.0066323671,\n",
       " 0.0061241528,\n",
       " 0.0078262724,\n",
       " 0.008080326,\n",
       " 0.008139113,\n",
       " 0.0063292431,\n",
       " 0.0072060614,\n",
       " 0.0070407917,\n",
       " 0.0074252742,\n",
       " 0.0065771863,\n",
       " 0.0069048833,\n",
       " 0.0073461873,\n",
       " 0.0067412853,\n",
       " 0.0069296435,\n",
       " 0.0064825597,\n",
       " 0.007219404,\n",
       " 0.0068469266,\n",
       " 0.0077704703,\n",
       " 0.0069724596,\n",
       " 0.006826635,\n",
       " 0.008205818,\n",
       " 0.0075009903,\n",
       " 0.0068179113,\n",
       " 0.0066721505,\n",
       " 0.0067604701,\n",
       " 0.0072013806,\n",
       " 0.0073118275,\n",
       " 0.0074111787,\n",
       " 0.0076078796,\n",
       " 0.0071833902,\n",
       " 0.0061519635,\n",
       " 0.0068201753,\n",
       " 0.0059591769,\n",
       " 0.0064401496,\n",
       " 0.0066616861,\n",
       " 0.0053854538,\n",
       " 0.0061045592,\n",
       " 0.0068218331,\n",
       " 0.0058499253,\n",
       " 0.0070739207,\n",
       " 0.0069165751,\n",
       " 0.0058074463,\n",
       " 0.0076364712,\n",
       " 0.0061630495,\n",
       " 0.0066662608,\n",
       " 0.0060664117,\n",
       " 0.0064996374,\n",
       " 0.0055533308,\n",
       " 0.0061474051,\n",
       " 0.0064429529,\n",
       " 0.0064313714,\n",
       " 0.0058432003,\n",
       " 0.005495599,\n",
       " 0.0068134768,\n",
       " 0.006342161,\n",
       " 0.0062614791,\n",
       " 0.0075105983,\n",
       " 0.0060796211,\n",
       " 0.0055651711,\n",
       " 0.0053329538,\n",
       " 0.0052894801,\n",
       " 0.0050693392,\n",
       " 0.0058996645,\n",
       " 0.0057691596,\n",
       " 0.0052890265,\n",
       " 0.0060661994,\n",
       " 0.0053344495,\n",
       " 0.0050778752,\n",
       " 0.0075944201,\n",
       " 0.0060721883,\n",
       " 0.0058763241,\n",
       " 0.0066177063,\n",
       " 0.0055343206,\n",
       " 0.0052381405,\n",
       " 0.0063081328,\n",
       " 0.0062680896,\n",
       " 0.0056896424,\n",
       " 0.0063056056,\n",
       " 0.0049089855,\n",
       " 0.0055118161,\n",
       " 0.0053732591,\n",
       " 0.0054354072,\n",
       " 0.0053608879,\n",
       " 0.0057633952,\n",
       " 0.0053190119,\n",
       " 0.0060175029]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(10, 20000, 128, dataloader, save_path='./Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_model(encode_dim, noise_dim=0, loadpath='./'):\n",
    "    \n",
    "    encoder = GeomEncoder(encode_dim, 1, 64, 64)\n",
    "    decoder = GeomDecoder(encode_dim, 0, 1, 64, 64)\n",
    "    encoder.load_state_dict(torch.load(loadpath + '/encoder_net.pth'))\n",
    "    decoder.load_state_dict(torch.load(loadpath + '/decoder_net.pth'))\n",
    "    \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeomDecoder(\n",
       "  (initial): TConvSet(\n",
       "    (convSet): Sequential(\n",
       "      (initial.10-512.transconv): ConvTranspose2d(10, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "      (initial.512.batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (initial.512.ReLU): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (pyramid_1.512-256.transconv): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (pyramid_1.256.batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (pyramid_1.256.ReLU): ReLU(inplace)\n",
       "    (pyramid_2.256-128.transconv): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (pyramid_2.128.batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (pyramid_2.128.ReLU): ReLU(inplace)\n",
       "    (pyramid_3.128-64.transconv): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (pyramid_3.64.batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (pyramid_3.64.ReLU): ReLU(inplace)\n",
       "    (final_layer.64-1.transconv): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (final_layer.1.batchnorm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (final_layer.1.ReLU): ReLU(inplace)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder = load_model(encode_dim=10, loadpath=\"/home/zhaocheng/Research/DeepOpticsV2/GeomGenerator/Models/18000\")\n",
    "encoder.cuda()\n",
    "decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0050 -0.3153  1.5311  ...   0.4010 -0.3877 -0.7968\n",
      "-0.3450 -0.8580 -0.9402  ...  -0.4913 -1.1406  1.0778\n",
      "-1.7939 -2.4345  0.0230  ...  -0.8947 -1.4143 -2.0140\n",
      "          ...             ⋱             ...          \n",
      "-1.3286 -1.9425  1.1320  ...   0.3551  1.6288 -0.5600\n",
      " 0.6570 -1.4196 -0.1883  ...  -1.2224  1.9462 -2.4900\n",
      "-1.8160  0.0480  0.9738  ...  -0.8542 -2.0262 -0.2787\n",
      "[torch.cuda.FloatTensor of size 128x10 (GPU 0)]\n",
      "\n",
      "[[-0.00500587 -0.31528282  1.53109717 ...,  0.40103978 -0.38766012\n",
      "  -0.79675519]\n",
      " [-0.34500268 -0.85801649 -0.9402051  ..., -0.4912774  -1.14058185\n",
      "   1.07781792]\n",
      " [-1.79387796 -2.43451428  0.02302435 ..., -0.89473218 -1.41428971\n",
      "  -2.01401234]\n",
      " ..., \n",
      " [-1.32863319 -1.94246292  1.13204026 ...,  0.35508212  1.62875056\n",
      "  -0.56003934]\n",
      " [ 0.65703112 -1.41960216 -0.18833512 ..., -1.22238243  1.94623899\n",
      "  -2.49004412]\n",
      " [-1.81604731  0.04801644  0.97379637 ..., -0.85420161 -2.0262177\n",
      "  -0.27869701]]\n",
      "Variable containing:\n",
      "-0.6593 -0.3309 -0.0759 -1.1343 -0.1074 -0.4417  0.3088 -0.8890  0.4056  0.0303\n",
      "[torch.cuda.FloatTensor of size 1x10 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataiter = dataloader.dataloader(128)\n",
    "input_data = Variable(next(dataiter).cuda(), requires_grad=False)\n",
    "latent = encoder(input_data)\n",
    "print(latent)\n",
    "z = latent.cpu().data.numpy()\n",
    "print(z)\n",
    "z1 = torch.mean(latent, 0, True) * 1\n",
    "print(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.2983  0.2231  0.2930  ...   1.0904  1.0995  0.4397\n",
      "  0.9655  0.9533  1.0010  ...   1.0933  1.1171  0.2034\n",
      "  0.8054  0.7816  0.8760  ...   1.0947  1.1048  0.2561\n",
      "           ...             ⋱             ...          \n",
      "  0.6344  0.3898  0.6864  ...   1.0968  1.0933  0.7986\n",
      "  0.6101  0.4226  0.6386  ...   1.0682  0.9996  0.5552\n",
      "  0.8132  0.6761  0.8524  ...   1.0892  1.0219  0.6110\n",
      "[torch.cuda.FloatTensor of size 1x1x64x64 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABSCAYAAABE4S/MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACpFJREFUeJzt3V+InFcZx/Hv01nXJdsEsmn+bP40bWxqsWgWmkTQImgw\nmwakFaFNblpQiF545VXAa8UK3ogXEkFoBVtLoLSIdEmCqLSWJtWEtto0a5t0kzRpkq7tNm3N7uZ4\nMTObcZ3ZfWfef+ec9/eBZXdnZ2fPb57zPvPueWfmNeccIiISvpvKHoCIiGRDDV1EJBJq6CIikVBD\nFxGJhBq6iEgk1NBFRCKRqqGb2S4zO2lm42a2P6tB+aYKOZUxHlXIWYWMvbBen4duZjXgDeDrwFng\nKLDXOfeP7IZXvirkVMZ4VCFnFTL2Ks0e+nZg3Dn3pnPuGvAkcH82w/JKFXIqYzyqkLMKGXvSl+J3\n1wETLd+fBb44/0pmtg/YB1Cjds8SlgFw5xc+SvGni7Pp1j7en7rOMhtyU0xeBn7AvJytGQeX2D13\n3dFfwkh7lyQjdK5lCAYYZJZpltlQ81/SKeDx+derYi1Dy9nMuHXLgDs9MQ3wMJHN1/mmmLzsnFu5\n2PXSNPREnHMHgAMAW7cMuJfGVjR+sqLzL3nk4O8/ZOyPH/H2Ezs47A6eaXed/8+4odAxppUkIyxU\nS/81M/7qZ/Ux14YnL7e7XnVrGU7OG7VcxfbRCa5M/qft9UKer61G144sWMtWaZZczgGts2B947Ko\nrFtTY+LcdOtF0eWsaMZ+IssIla1ldBl7laahHwU2m9ntZtYP7AGezWZY/tg2MsD4W9P88sWjAEaE\nOZsZP3ZXIfKMb709zbVrDmCIyDJC9Wp5/bqDCDP2queG7pybAb4PjAH/BJ5yzr2W1cB80ddn/PzH\nK7lv73mAu4kwZzPj3/kLRJ7xvr3nufsrZwDeiy0jFFvL0bUjjK4dyeOmF9Ray9feuAYRztdepXoe\nunPuD865O51zn3HO/SirQflm945BXn9+I8CrsebcvWOQL9kuiDzj689v5NSLtwFcKHk4uSmilq2N\nvIzG3qzl5+/6NLHO117olaIJlbEnIhISbSPly/1ZLiJSHZ2a+tj54wWPpJq0hy4iuStrvb1q1NAT\n0h6GSF2axqymni8tuSRUn4jjZQ9DJHghL8t084BURh7toYtIYnnuYfu+LNPt2MrIo4YeoOZE8Xny\nJxVLDslObHOiyCxBLbl0e8eE8C9cWs37JLSsMW2wko92c6TMeT52/njP87ao7TTqPXQ1jTCE9mAk\n1eX7XA1mD933R8ai6EHKL/PrEcs866SZT/OwN6NrR3KdI0E09CwmT9rGPnb+OLXh1MNIJcaNKOQG\n2K4eVWnwrblinJd5yrOpR73k0k6Mky+0phFjDTppd4AvpoPaUJ9/zY8qyCJnXrX3fg89lkmfl5A3\nopDH3q1O8zi2JcE899xjuY/y5H1Dr7LWjT3GB7a81xPzlHU9Ymvs0D5Lr/ebb/eLr8cSKrfkEiLf\nJk0aMWWR7vnWmNNqXW7qNlse24IauohHqvCAF1tTb1V2NjV0T8W6Yc+f8KEeHMxzw43toGlaZTfJ\nbpU5XjV0D1VxQw4xcxHP7AjxfpHyeN3QqzqZu2kSId5HnfKFmAXy3yOLbW89piy+8fpZLrE+uyOJ\npNlD+3e0qdOzBELN3G4pKWtVedGS9M7rPXSJX6xNKdZckkxZ9VdDl9LF+irDGDMVLeT7sIx57fWS\nSx5CmSAhn9WlV0mXmUJ6EU5ey4YhZG+nikuoRb7vTeUaegiqOOmbYjxu4uurCn0X6oPWQvR+6DIn\nxgneTpKcId4XWY05xOxSDO/30H14m84bfzf/k0RXcamlnVjzJs0V49687ydYjoH3DT1LmiQSik47\nMprDspCgllzSTGZtCBIqzV1JKrg99DIOMDX/ZhFnLGqXTxu0hD4HYlxC8lGihm5mp4EpYBaYcc5t\nNbMh4HfAbcBp4EHn3GQ+w+xd0g1h07bTLL35Jmo16KsZL41t4L3JWfZ87wJnJmbYuKEPoJbrYFs0\nn+2R9Ya8UM4X3AWAzWa23MdaJuVbLfOiWs5w8dIMoWfMUjdLLl91zo0457Y2vt8PHHHObQaONL4v\nzPz3IW7X+LpthkcOruNvh2/lpbENADz6i0l23LuEky9sZMe9SwDWZDD0xPLaK+uU88u2C+oP3IXW\nMg++1TIvVa/lsptvgggyZiXNGvr9wGONrx8DHkg/nHTSvNl8O8+OXeXhB5cCND8vT32jHmrNCVzB\ng1pmTbUsT7fLLYttu60ZVyyvgQcZfZG0oTvgsJm9bGb7Gpetds690/j6ArC63S+a2T4zO2Zmxy5d\nmU053PyYwc6HzrFt5wQHfvM+ABcvzTK8ur4qtWZVDTosUYWSERbPCUyjWnqfEeKs5fxmvljGvvqn\noDLmKelB0Xudc+fMbBVwyMxeb/2hc86ZmWv3i865A8ABgK1bBtpexwd/fmY964b7ePfyDKMPneeu\nO/r/5+dm1vF3Q8kIi+dsUC3xOyOoljBXy6AzZinRHrpz7lzj87vA08B24KKZDQM0Pr+b1yCLsG64\n/ti26pY+HrhvkKPHP2H1yhrvXJwBaH6eKW+E2VgsJ/ApVMsghFLLNMufi2WcnnbgQUZfLNrQzWzQ\nzJY2vwZ2Aq8CzwKPNK72CPBMXoPM29WPrjP14fW5rw/96WPu/mw/39g5yONPTQE0P/+7vFGmlyQn\nsALV0nuh1TLJca35P0+S8crkLHiS0QdJllxWA083/rXpA37rnHvOzI4CT5nZd4AzwIP5DTNfFy/N\n8q1v1w8HzMzA3m/ezK6vDbJtZIA9373Ar5/4gI3r+wDeWfCGPLdYzr+65wCWAT8pc5xpqJZ+17Kb\nN19LUssP6g3fq4xlMueKW1raumXANZ96FKLa8PjLLU/bbCvkjKNrRzjsDi6aEcLOCaplq5Bzbh+d\n4NiJTzofFGkIOWM3tQzqpf8iItKZGrqISCTU0EVEIqGGLiISiUIPiprZFHCysD+Y3C3A5QTX2+ic\nW7nQFczsEnA14e0VKbOM4G0tk2YE1XJO4LUMOSNknLPot889meRIbdHM7FhW43LOrczy9rKSw5i8\nq2XWGVXL8lQhI2SfU0suIiKRUEMXEYlE0Q39QMF/L6msx+VjTmX05zbTUi3Lv72sZDquQg+KiohI\nfrTkIiISCTV0EZFIFNbQzWyXmZ00s3EzK+0cgGZ22sxeMbPjZnascdmQmR0ys1ONzz2dnsyXjI2x\nRJ9TGePI2BhL9DnzzDjHOZf7B/UzrP8L2AT0AyeAzxXxt9uM5TRwy7zLfgrsb3y9H3g05IxVyamM\ncWSsSs68MrZ+FLWHvh0Yd8696Zy7BjxJ/STTvsjihNe+Z4Rq5FTGZHzPCNXImUXGOUU19HXARMv3\nZxuXlaHnE14vwqeMUI2cyhhHRqhGzrwyzin6pf8+6PmE14GpQk5ljCMjVCNn7hmL2kM/B7SeLmR9\n47LCufxOeO1NRqhGTmWMIyNUI2eOGecU1dCPApvN7HYz6wf2UD/JdKEs3xNee5ERqpFTGePICNXI\nmXPGGwo8wrsbeIP6EecflnSUeRP1o9wngNea46B+dvQjwCngMDAUasaq5FTGODJWJWfeGZsfeum/\niEgk9EpREZFIqKGLiERCDV1EJBJq6CIikVBDFxGJhBq6iEgk1NBFRCLxXyh0Z3nQZGaiAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5bdf44f630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# output = decoder(latent)\n",
    "output = decoder(z1*0.01)\n",
    "print(output)\n",
    "img = output.cpu().data[0,0,:,:]\n",
    "img.clamp_(0,1)\n",
    "img = img.numpy()\n",
    "img = recover_img(img, True)\n",
    "# print(img)\n",
    "# plt.imshow(img)\n",
    "output2 = decoder(latent)\n",
    "imgs = [img]\n",
    "for i in range(5):\n",
    "    img = output2.cpu().data[i,0,:,:]\n",
    "    img.clamp_(0,1)\n",
    "    img = img.numpy()\n",
    "    imgs.append(recover_img(img, True))\n",
    "#     plt.imshow(img)\n",
    "for i in range(6):\n",
    "    plt.subplot(1,6,i+1)\n",
    "    plt.imshow(imgs[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
